from opencage.geocoder import OpenCageGeocode
from newsapi import NewsApiClient
from datetime import datetime
from django.utils.timezone import make_aware
from django.core.cache import cache
from app.models import NewsArticle, LocalNews
import os
import time
import logging
from dotenv import load_dotenv

# Load environment variables
load_dotenv()
API_KEY = os.getenv("NEWSAPI_KEY")
GEOCODING_API_KEY = os.getenv("GEOCODING_API_KEY")  # OpenCage API Key

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

newsapi = NewsApiClient(api_key=API_KEY)
geocoder = OpenCageGeocode(GEOCODING_API_KEY)  # OpenCage client

CATEGORIES = ["technology", "business", "sports", "entertainment", "health", "science", "general"]
CACHE_TIMEOUT = 6 * 60 * 60  # 6 hours


def fetch_news():
    """Fetches global news articles and stores them in the database with caching."""
    cache_key = "latest_news_fetched"
    if cache.get(cache_key):
        logger.info("‚úÖ Using cached news, skipping API request")
        return

    logger.info("üì° Starting news fetch...")

    for category in CATEGORIES:
        logger.info(f"üîç Fetching {category.capitalize()} news...")
        try:
            top_headlines = newsapi.get_top_headlines(category=category, language="en", country="us")

            if not top_headlines.get("articles"):
                logger.warning(f"‚ö†Ô∏è No articles found for {category}!")
                continue

            for article in top_headlines["articles"]:
                obj, created = NewsArticle.objects.get_or_create(
                    url=article["url"],
                    defaults={
                        "title": article["title"],
                        "source": article["source"]["name"],
                        "published_at": make_aware(
                            datetime.strptime(article["publishedAt"], "%Y-%m-%dT%H:%M:%SZ")
                        ),
                        "category": category.capitalize(),
                    },
                )
                if created:
                    logger.info(f"‚úÖ Added: {article['title']}")
                else:
                    logger.info(f"üîπ Skipped duplicate: {article['title']}")

        except Exception as e:
            logger.error(f"‚ùå Error fetching {category} news: {str(e)}")
            time.sleep(5)

    cache.set(cache_key, datetime.now(), CACHE_TIMEOUT)
    logger.info(f"‚úÖ News fetch completed & cached for {CACHE_TIMEOUT // 3600} hours")


def reverse_geocode(lat, lon):
    """Converts latitude and longitude to a city or region name using OpenCage API."""
    try:
        results = geocoder.reverse_geocode(lat, lon)

        if results:
            components = results[0]["components"]
            city = components.get("city") or components.get("town") or components.get("village")
            county = components.get("county")
            state = components.get("state")
            country = components.get("country")

            if city:
                location_name = f"{city}, {state}" if state else city
                logger.info(f"üìç Identified Location: {location_name}, {country}")
                return location_name
            elif county:
                location_name = f"{county}, {state}" if state else county
                logger.info(f"üìç Using county as fallback: {location_name}, {country}")
                return location_name
            elif state:
                logger.info(f"üìç Using state as fallback: {state}, {country}")
                return state
            else:
                logger.warning("‚ö†Ô∏è No valid city, county, or state found.")
                return None

        logger.warning("‚ö†Ô∏è No geocoding results found.")
        return None

    except Exception as e:
        logger.error(f"‚ùå Error in reverse geocoding: {str(e)}")
        return None


def fetch_local_news(lat, lon):
    """Fetches local news based on user's latitude & longitude."""
    cache_key = f"local_news_fetched_{lat}_{lon}"
    if cache.get(cache_key):
        logger.info("‚úÖ Using cached local news, skipping API request")
        return
    
    city_name = reverse_geocode(lat, lon)
    
    if not city_name:
        logger.warning("‚ö†Ô∏è No city found, using 'local news' query.")
        query = "local news"
    else:
        query = city_name

    logger.info(f"üì° Fetching local news for location: {query}...")

    try:
        for category in CATEGORIES:
            logger.info(f"üîç Fetching {category.capitalize()} local news...")
            top_headlines = newsapi.get_everything(q=query, language="en")

            if not top_headlines.get("articles"):
                logger.warning(f"‚ö†Ô∏è No articles found for {category} in {query}!")
                continue

            for article in top_headlines["articles"]:
                obj, created = LocalNews.objects.get_or_create(
                    url=article["url"],
                    defaults={
                        "title": article["title"],
                        "source": article["source"]["name"],
                        "published_at": make_aware(
                            datetime.strptime(article["publishedAt"], "%Y-%m-%dT%H:%M:%SZ")
                        ),
                        "category": category.capitalize(),
                        "location": city_name,
                    },
                )
                if created:
                    logger.info(f"‚úÖ Added: {article['title']} ({category})")
                else:
                    logger.info(f"üîπ Skipped duplicate: {article['title']}")

    except Exception as e:
        logger.error(f"‚ùå Error fetching local news: {str(e)}")
        return []

    cache.set(cache_key, datetime.now(), CACHE_TIMEOUT)
    logger.info(f"‚úÖ Local news fetch completed & cached for {CACHE_TIMEOUT // 3600} hours")
